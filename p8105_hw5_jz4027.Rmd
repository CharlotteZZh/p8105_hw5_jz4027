---
title: "p8105_hw5_jz4027"
author: "Charlotte Zhang"
date: "2025-11-04"
output: github_document
---
```{r, include = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(broom)
library(purrr)

set.seed(1)
```

# Problem 1
```{r}
# Write the function
bday_sim = function(n_room) {
  birthdays = sample(1:365, n_room, replace = TRUE)
  repeated_bday = length(unique(birthdays)) < n_room
  repeated_bday
}

bday_sim(20)
```

```{r}
# Run the simulation 10000 times for each group size from 2 to 50

bday_sim_results = 
  expand_grid(
    bdays = 2:50, 
    iter = 1:10000
  ) |> 
  mutate(
    result = map_lgl(bdays, bday_sim)
  ) |> 
  group_by(
    bdays
  ) |> 
  summarize(
    prob_repeat = mean(result)
  )
```

```{r}
# A plot showing the probability of repeated birthday for each group size
bday_sim_results |> 
  ggplot(aes(x = bdays, y = prob_repeat)) + 
  geom_point() + 
  geom_line() + 
  labs(
    title = "Birthday Simulation",
    x = "Number of People in the Room",
    y = "Probability of Shared Birthday"
  ) + 
  theme_minimal()
```
The plot shows that as the number of people in the room increases, the probability of shared birthday also increases. The probability of shared birthday approaches 1 as the number of people approaching 50. Around 23 people, the probability is approximately 0.5, meaning that there is a 50% chance that two people share the same birthday.

# Problem 2
```{r}
# Simulate the data and conduct one sample t-test
# 7 mu, 5000 simulations each, sample n = 30
sim_results <- expand_grid(
  mu = 0:6,
  iter = 1:5000
) |> 
  mutate(
    data = map(mu, ~ rnorm(30, mean = .x, sd = 5)),
    test = map(data, ~ t.test(.x, mu = 0)),
    tidy = map(test, tidy)
  ) |> 
  unnest(tidy) |> 
  select(mu, estimate, p.value)
```

```{r}
power_results <- sim_results |>
  group_by(mu) |>
  summarize(
    power = mean(p.value < 0.05),
    avg_estimate_all = mean(estimate),
    avg_estimate_rejected = mean(estimate[p.value < 0.05])
  )
```

```{r}
# Power vs Effect Size graph
power_results |>
  ggplot(aes(x = mu, y = power)) +
  geom_point() +
  geom_line() +
  labs(
    x = "True Mean (μ)",
    y = "Power (probability of correctly rejecting a false null)",
    title = "Power vs True Mean"
  ) +
  theme_minimal()
```
* The power increases as the true mean increases because the effect size gets larger when mu moves further away from 0, so it is easier to detect and reject the null. For example, the power reaches 1.0 for true means greater than or equal to 4. 
* The null hypothesis is correct when mu is 0, so the power is about 0.05 which is valid since the alpha here is 0.05. 
* True mean increases -> effect size increases, effect size increase -> power increases

```{r}
# Mean vs. Estimated Mean graph
power_results |>
  ggplot(aes(x = mu)) +
  geom_line(aes(y = avg_estimate_all, color = "All samples"), linewidth = 1) +
  geom_line(aes(y = avg_estimate_rejected, color = "Null rejected only"), linewidth = 1) +
  labs(
    x = "True Mean (μ)",
    y = "Average Estimated Mean",
    title = "Average Estimates vs True Mean",
    color = "Condition"
  ) +
  theme_minimal()
```
* The average estimated mean across all samples closely matches the true mean, suggesting that the sample means are unbiased. 
* However, the average estimated mean across only samples where null is rejected does not match the true mean, especially for mu equals to 1, 2, and 3. We reject the null when the sample mean is extremely large (far from 0), so by looking only at samples for which the null was rejected, we are focusing on those overrepresented larger-than-average estimates. For large true means, almost all sample means are extremely far from 0 and almost all tests reject the null, so not a big difference between the red and blue line in the graph. For small true means, only unusually large sample means lead to null rejection, making the average of rejected samples noticeably higher. 

# Problem 3
```{r}
# import data
homicides_df <- read_csv("./homicide-data.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names()
```
This dataset has `r nrow(homicides_df)` rows and `r ncol(homicides_df)` columns, where each row represents a single homicide case. The variables include `r names(homicides_df)`

```{r}
# create city_state variable, summarize homicides within each city_state
cities_summary <- homicides_df |>
  mutate(city_state = paste(city, state, sep = ", ")) |>
  group_by(city_state) |>
  summarize(
    total = n(),
    unsolved = sum(disposition %in% c("Open/No arrest", "Closed without arrest"))
  )
knitr::kable(cities_summary)
```

```{r}
# filter out Baltimore MD
baltimore <- cities_summary |> 
  filter(city_state == "Baltimore, MD")

# prop.test
baltimore_proptest <- prop.test(baltimore$unsolved, baltimore$total)

# pull the info
baltimore_results <- broom::tidy(baltimore_proptest) |>
  select(estimate, conf.low, conf.high)
knitr::kable(baltimore_results)
```

```{r}
each_city_results <- cities_summary |>
  mutate(
    cities_proptest = map2(unsolved, total, ~suppressWarnings(prop.test(.x, .y))),
    cities_tidy = map(cities_proptest, broom::tidy)
  ) |>
  unnest(cities_tidy) |>
  select(city_state, estimate, conf.low, conf.high)
knitr::kable(each_city_results)
```

```{r}
each_city_results |>
  ggplot(aes(y = fct_reorder(city_state, estimate), 
             x = estimate)) +
  geom_point() +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) +
  labs(
    title = "Unsolved Homicides Proportion and CI by City",
    x = "Unsolved Homicides Proportion",
    y = "City_State"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 6)) 
```